{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re, nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    268974\n",
      "0    188856\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"enriched_data_crawler.csv\")\n",
    "print(df.label.value_counts())\n",
    "arr = [i for i in range(len(df.loc[df.label == 0])) if i % 3 == 1]\n",
    "df_2 = pd.read_csv(\"../data/movie_reviews.csv\")\n",
    "df = pd.concat([df_2,df.loc[df.label == 0].iloc[arr].iloc[:26000]])\n",
    "#df = pd.read_csv(\"../data/movie_reviews.csv\")\n",
    "df = df[~df.text.isnull()]\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    89658\n",
       "0    88768\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stems = [stemmer.stem(word) for word in word_list]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        df.text, \n",
    "        df.label,\n",
    "        test_size=0.2, \n",
    "        random_state=42, stratify=df.label)\n",
    "\n",
    "pipeline = Pipeline([('vectorizer', TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 3),\n",
    "                              analyzer = 'word', binary = True, max_df= 0.75)), \n",
    "                     ('classifier', LogisticRegression(C = 100, class_weight='balanced'))])\n",
    "model = pipeline.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866810513927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.84      0.86     17754\n",
      "          1       0.85      0.90      0.87     17932\n",
      "\n",
      "avg / total       0.87      0.87      0.87     35686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "BASE_DIR = ''\n",
    "TEXT_DATA_DIR = BASE_DIR + '../data/test'\n",
    "TEXT_DATA_FILE_1 = \"rt-polarity_neg.txt\"\n",
    "TEXT_DATA_FILE_2 = \"rt-polarity_pos.txt\"\n",
    "HEADER = True\n",
    "\n",
    "def load_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in [TEXT_DATA_FILE_1, TEXT_DATA_FILE_2]:\n",
    "        with open(os.path.join(TEXT_DATA_DIR, i), \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "            if HEADER:\n",
    "                _ = next(f)\n",
    "            if i[-7:-4] == \"pos\":\n",
    "                temp_y = 1\n",
    "            else: temp_y = 0\n",
    "            for line in f:\n",
    "                x.append(line.rstrip(\"\\n\"))\n",
    "                y.append(temp_y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "data, labels = load_data()\n",
    "labels = np.asarray(labels, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({\"text\": data, \"label\": labels})\n",
    "temp.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10660, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv(\"test.csv\")\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829174484053\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.75      0.81      5330\n",
      "          1       0.78      0.91      0.84      5330\n",
      "\n",
      "avg / total       0.84      0.83      0.83     10660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data)\n",
    "\n",
    "print (accuracy_score(labels, y_pred))\n",
    "print(classification_report(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84296435272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.79      0.83      5330\n",
      "          1       0.81      0.89      0.85      5330\n",
      "\n",
      "avg / total       0.85      0.84      0.84     10660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data)\n",
    "\n",
    "print (accuracy_score(labels, y_pred))\n",
    "print(classification_report(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "trained_model = joblib.load('/Users/vitaliyradchenko/Documents/udsc/check3/xray/preprocess1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=Tr...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10660"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836303939962\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.77      0.82      5330\n",
      "          1       0.80      0.90      0.85      5330\n",
      "\n",
      "avg / total       0.84      0.84      0.84     10660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = trained_model.predict(data)\n",
    "\n",
    "print (accuracy_score(labels, y_pred))\n",
    "print(classification_report(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152610.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,len(df),3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    268974\n",
       "0    188856\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26706"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[range(0,len(df),3), \"label\"].value_counts()[0] - df.loc[range(0,len(df),3), \"label\"].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ ' do ai rap television do cute however dim furthermore breathtaking pistol include do improved away',\n",
       "       ' breathe ah soul broadcast breathe beautiful although tedious also affecting doer enjoy breathe superior somewhere',\n",
       "       '\"For all the pleasure there is in seeing effective, great-looking black women grappling with major life issues on screen, Waiting to Exhale is an uneven piece.\"',\n",
       "       ' entire breathtaking enjoyment effective do swank noticing impressive slate mate confront alongside large-scale growth point above net into do an unequal specimen',\n",
       "       ' complete affecting thrill skilled breathe fly regarding useful jet mariner contend along dominant heart affair about curtain facing breathe an patchy slice',\n",
       "       '\"With one possible exception, none of its women is at all likable.\"',\n",
       "       ' sole probable rejection nobody concerning mine mate do on entire enjoyable',\n",
       "       ' solitary available omission nothing about owned mariner breathe by complete sympathetic',\n",
       "       '\"When Robin asks, \\'Don\\'t we hear this on Sally and Oprah every day?\\' you may be inclined to agree.\"',\n",
       "       ' challenge personally get that above furthermore each one daylight you be allowed do apt into concur'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].text[40:50].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62952, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].iloc[arr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
