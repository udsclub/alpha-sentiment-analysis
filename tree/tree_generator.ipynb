{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import six.moves.cPickle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "\n",
    "negatives = {\n",
    "    \"didn't\": \"didn_`_t\",\n",
    "    \"couldn't\": \"couldn_`_t\",\n",
    "    \"don't\": \"don_`_t\",\n",
    "    \"wouldn't\": \"wouldn_`_t\",\n",
    "    \"doesn't\": \"doesn_`_t\",\n",
    "    \"wasn't\": \"wasn_`_t\",\n",
    "    \"weren't\": \"weren_`_t\",\n",
    "    \"shouldn't\":\"shouldn_`_t\",\n",
    "    \"isn't\": \"isn_`_t\",\n",
    "    \"aren't\": \"aren_`_t\",\n",
    "}\n",
    "\n",
    "MODEL_NAME = \"model_movie_2017-03-10-09-440.001.hdf5\"\n",
    "TOKENIZER = \"movie_2017-03-10-09-44_tokenizer\"\n",
    "MAX_SEQUENCE_LENGTH = 110\n",
    "\n",
    "tokenizer = six.moves.cPickle.load(open(TOKENIZER, \"rb\"))\n",
    "model = load_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('<br />', ' ')\n",
    "    text = ' '.join(tweet_tokenizer.tokenize(text))\n",
    "    for k, v in negatives.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text = preprocess(text)\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return model.predict_proba(X, verbose=0)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99685258"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This show is a must have if you enjoy shows with family Michael J fox does a spectacular job playing Alex Keaton and the series finale is great'\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parser http://nlp.stanford.edu:8080/parser/index.jsp\n",
    "# stanford realization http://nlp.stanford.edu:8080/sentiment/rntnDemo.html\n",
    "\n",
    "tree = '''(ROOT\n",
    "  (S\n",
    "    (NP\n",
    "      (NP (JJ Good) (NN film))\n",
    "      (, ,)\n",
    "      (PP (CC but)\n",
    "        (NP (PRP I))))\n",
    "    (VP (MD will) (RB not)\n",
    "      (VP (VB recommend)\n",
    "        (NP (PRP it))))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tree(x, name):\n",
    "    \n",
    "    new_tree = parse_nested(tree)\n",
    "    update_keys(new_tree)\n",
    "    tree_str = ''\n",
    "    a = nested_list_to_tree(new_tree, tree_str)\n",
    "    cf = CanvasFrame()\n",
    "    t = Tree.fromstring(a)\n",
    "    tc = TreeWidget(cf.canvas(),t)\n",
    "    cf.add_widget(tc,10,10) # (10,10) offsets\n",
    "    cf.print_to_file('{}.ps'.format(name))\n",
    "    cf.destroy()\n",
    "    return \n",
    "\n",
    "def parse_nested(text, left=r'[(]', right=r'[)]', sep=r' '):\n",
    "    pat = r'({}|{}|{})'.format(left, right, sep)\n",
    "    tokens = re.split(pat, text)    \n",
    "    stack = [[]]\n",
    "    for x in tokens:\n",
    "        if not x or re.match(sep, x): continue\n",
    "        if re.match(left, x):\n",
    "            stack[-1].append([])\n",
    "            stack.append(stack[-1][-1])\n",
    "        elif re.match(right, x):\n",
    "            stack.pop()\n",
    "            if not stack:\n",
    "                raise ValueError('error: opening bracket is missing')\n",
    "        else:\n",
    "            \n",
    "            temp = x.rstrip().split()\n",
    "            if len(temp) == 2:\n",
    "                for i in temp:\n",
    "                    stack[-1].append(temp[1])\n",
    "            else:\n",
    "                for i in temp:\n",
    "                    stack[-1].append(i)\n",
    "    if len(stack) > 1:\n",
    "        print(stack)\n",
    "        raise ValueError('error: closing bracket is missing')\n",
    "    return stack.pop()[0]\n",
    "\n",
    "def update_keys(node):\n",
    "    if isinstance(node, str): # в листе\n",
    "        return node\n",
    "    items = []\n",
    "    for child in node[1:]:\n",
    "        items.append(update_keys(child))\n",
    "    res = ' '.join(items)\n",
    "    node[0] = predict(res)\n",
    "    return res\n",
    "\n",
    "def nested_list_to_tree(nested_list, tree):\n",
    "    if isinstance(nested_list, str): # в листе\n",
    "        return tree + str(nested_list)\n",
    "    tree += \"(\" + str(nested_list[0]) + ' '\n",
    "    for child in nested_list[1:]:\n",
    "        tree = nested_list_to_tree(child, tree)\n",
    "    return tree + ')'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_tree(tree, 'new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(0.219898 (0.219898 (0.482649 (0.42032 This)(0.558865 movie))(0.271697 (0.451553 cares)(0.146194 (0.507136 about)(0.344677 (0.559251 (0.559251 cleverness))(0.492164 ,)(0.965898 (0.965898 wit))(0.303927 or)(0.694185 (0.396816 (0.389445 any)(0.485143 other)(0.489174 kind))(0.998065 (0.47998 of)(0.997173 (0.857307 intelligent)(0.845813 humor)))))))(0.492164 .)))'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
